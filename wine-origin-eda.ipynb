{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, explained_variance_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ucimlrepo in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (0.0.7)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from ucimlrepo) (2024.7.4)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from ucimlrepo) (1.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2020.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (1.18.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=1.0.0->ucimlrepo) (1.15.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from tensorflow) (1.31.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from tensorflow) (0.35.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from tensorflow) (0.10.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from tensorflow) (3.11.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from tensorflow) (1.18.5)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (50.3.0.post20201103)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.22.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
      "Requirement already satisfied: aiohttp<4.0.0dev,>=3.6.2; python_version >= \"3.6\" in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (3.6.3)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from aiohttp<4.0.0dev,>=3.6.2; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (20.2.0)\n",
      "Requirement already satisfied: yarl<1.6.0,>=1.0 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from aiohttp<4.0.0dev,>=3.6.2; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (1.5.1)\n",
      "Requirement already satisfied: multidict<5.0,>=4.5 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from aiohttp<4.0.0dev,>=3.6.2; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.7.5)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in c:\\users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages (from aiohttp<4.0.0dev,>=3.6.2; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install ucimlrepo\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "data = fetch_ucirepo(id=109).data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malicacid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity_of_ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>0D280_0D315_of_diluted_wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alcohol  Malicacid   Ash  Alcalinity_of_ash  Magnesium  Total_phenols  \\\n",
       "0    14.23       1.71  2.43               15.6        127           2.80   \n",
       "1    13.20       1.78  2.14               11.2        100           2.65   \n",
       "2    13.16       2.36  2.67               18.6        101           2.80   \n",
       "\n",
       "   Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity   Hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "\n",
       "   0D280_0D315_of_diluted_wines  Proline  \n",
       "0                          3.92     1065  \n",
       "1                          3.40     1050  \n",
       "2                          3.17     1185  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class\n",
       "0      1\n",
       "1      1\n",
       "2      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.targets.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malicacid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity_of_ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>0D280_0D315_of_diluted_wines</th>\n",
       "      <th>Proline</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alcohol  Malicacid   Ash  Alcalinity_of_ash  Magnesium  Total_phenols  \\\n",
       "0    14.23       1.71  2.43               15.6        127           2.80   \n",
       "1    13.20       1.78  2.14               11.2        100           2.65   \n",
       "2    13.16       2.36  2.67               18.6        101           2.80   \n",
       "\n",
       "   Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity   Hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "\n",
       "   0D280_0D315_of_diluted_wines  Proline  class  \n",
       "0                          3.92     1065      1  \n",
       "1                          3.40     1050      1  \n",
       "2                          3.17     1185      1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join the features and target back into one dataset\n",
    "dataset = data.features.join(data.targets)\n",
    "\n",
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alcohol                         0\n",
       "Malicacid                       0\n",
       "Ash                             0\n",
       "Alcalinity_of_ash               0\n",
       "Magnesium                       0\n",
       "Total_phenols                   0\n",
       "Flavanoids                      0\n",
       "Nonflavanoid_phenols            0\n",
       "Proanthocyanins                 0\n",
       "Color_intensity                 0\n",
       "Hue                             0\n",
       "0D280_0D315_of_diluted_wines    0\n",
       "Proline                         0\n",
       "class                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malicacid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity_of_ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>0D280_0D315_of_diluted_wines</th>\n",
       "      <th>Proline</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.000618</td>\n",
       "      <td>2.336348</td>\n",
       "      <td>2.366517</td>\n",
       "      <td>19.494944</td>\n",
       "      <td>99.741573</td>\n",
       "      <td>2.295112</td>\n",
       "      <td>2.029270</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>1.590899</td>\n",
       "      <td>5.058090</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>2.611685</td>\n",
       "      <td>746.893258</td>\n",
       "      <td>1.938202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.811827</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>3.339564</td>\n",
       "      <td>14.282484</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.124453</td>\n",
       "      <td>0.572359</td>\n",
       "      <td>2.318286</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.709990</td>\n",
       "      <td>314.907474</td>\n",
       "      <td>0.775035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.030000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.362500</td>\n",
       "      <td>1.602500</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.742500</td>\n",
       "      <td>1.205000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>500.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.050000</td>\n",
       "      <td>1.865000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.355000</td>\n",
       "      <td>2.135000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1.555000</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>673.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.677500</td>\n",
       "      <td>3.082500</td>\n",
       "      <td>2.557500</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>3.170000</td>\n",
       "      <td>985.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.830000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1680.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Alcohol   Malicacid         Ash  Alcalinity_of_ash   Magnesium  \\\n",
       "count  178.000000  178.000000  178.000000         178.000000  178.000000   \n",
       "mean    13.000618    2.336348    2.366517          19.494944   99.741573   \n",
       "std      0.811827    1.117146    0.274344           3.339564   14.282484   \n",
       "min     11.030000    0.740000    1.360000          10.600000   70.000000   \n",
       "25%     12.362500    1.602500    2.210000          17.200000   88.000000   \n",
       "50%     13.050000    1.865000    2.360000          19.500000   98.000000   \n",
       "75%     13.677500    3.082500    2.557500          21.500000  107.000000   \n",
       "max     14.830000    5.800000    3.230000          30.000000  162.000000   \n",
       "\n",
       "       Total_phenols  Flavanoids  Nonflavanoid_phenols  Proanthocyanins  \\\n",
       "count     178.000000  178.000000            178.000000       178.000000   \n",
       "mean        2.295112    2.029270              0.361854         1.590899   \n",
       "std         0.625851    0.998859              0.124453         0.572359   \n",
       "min         0.980000    0.340000              0.130000         0.410000   \n",
       "25%         1.742500    1.205000              0.270000         1.250000   \n",
       "50%         2.355000    2.135000              0.340000         1.555000   \n",
       "75%         2.800000    2.875000              0.437500         1.950000   \n",
       "max         3.880000    5.080000              0.660000         3.580000   \n",
       "\n",
       "       Color_intensity         Hue  0D280_0D315_of_diluted_wines      Proline  \\\n",
       "count       178.000000  178.000000                    178.000000   178.000000   \n",
       "mean          5.058090    0.957449                      2.611685   746.893258   \n",
       "std           2.318286    0.228572                      0.709990   314.907474   \n",
       "min           1.280000    0.480000                      1.270000   278.000000   \n",
       "25%           3.220000    0.782500                      1.937500   500.500000   \n",
       "50%           4.690000    0.965000                      2.780000   673.500000   \n",
       "75%           6.200000    1.120000                      3.170000   985.000000   \n",
       "max          13.000000    1.710000                      4.000000  1680.000000   \n",
       "\n",
       "            class  \n",
       "count  178.000000  \n",
       "mean     1.938202  \n",
       "std      0.775035  \n",
       "min      1.000000  \n",
       "25%      1.000000  \n",
       "50%      2.000000  \n",
       "75%      3.000000  \n",
       "max      3.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    71\n",
       "1    59\n",
       "3    48\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malicacid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity_of_ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>0D280_0D315_of_diluted_wines</th>\n",
       "      <th>Proline</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>13.69</td>\n",
       "      <td>3.26</td>\n",
       "      <td>2.54</td>\n",
       "      <td>20.0</td>\n",
       "      <td>107</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.80</td>\n",
       "      <td>5.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.82</td>\n",
       "      <td>680</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>12.42</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.19</td>\n",
       "      <td>22.5</td>\n",
       "      <td>108</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.06</td>\n",
       "      <td>1.06</td>\n",
       "      <td>2.96</td>\n",
       "      <td>345</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13.64</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.56</td>\n",
       "      <td>15.2</td>\n",
       "      <td>116</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.66</td>\n",
       "      <td>5.10</td>\n",
       "      <td>0.96</td>\n",
       "      <td>3.36</td>\n",
       "      <td>845</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>12.21</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.75</td>\n",
       "      <td>16.8</td>\n",
       "      <td>151</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1.28</td>\n",
       "      <td>3.07</td>\n",
       "      <td>718</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>13.77</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.68</td>\n",
       "      <td>17.1</td>\n",
       "      <td>115</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.68</td>\n",
       "      <td>6.30</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2.93</td>\n",
       "      <td>1375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>12.70</td>\n",
       "      <td>3.55</td>\n",
       "      <td>2.36</td>\n",
       "      <td>21.5</td>\n",
       "      <td>106</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.84</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.29</td>\n",
       "      <td>600</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>12.53</td>\n",
       "      <td>5.51</td>\n",
       "      <td>2.64</td>\n",
       "      <td>25.0</td>\n",
       "      <td>96</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.10</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.69</td>\n",
       "      <td>515</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>13.49</td>\n",
       "      <td>1.66</td>\n",
       "      <td>2.24</td>\n",
       "      <td>24.0</td>\n",
       "      <td>87</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.98</td>\n",
       "      <td>2.78</td>\n",
       "      <td>472</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>12.93</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2.70</td>\n",
       "      <td>21.0</td>\n",
       "      <td>96</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.75</td>\n",
       "      <td>4.60</td>\n",
       "      <td>0.77</td>\n",
       "      <td>2.31</td>\n",
       "      <td>600</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>13.05</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2.55</td>\n",
       "      <td>18.0</td>\n",
       "      <td>98</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.44</td>\n",
       "      <td>4.25</td>\n",
       "      <td>1.12</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Alcohol  Malicacid   Ash  Alcalinity_of_ash  Magnesium  Total_phenols  \\\n",
       "161    13.69       3.26  2.54               20.0        107           1.83   \n",
       "117    12.42       1.61  2.19               22.5        108           2.00   \n",
       "19     13.64       3.10  2.56               15.2        116           2.70   \n",
       "69     12.21       1.19  1.75               16.8        151           1.85   \n",
       "53     13.77       1.90  2.68               17.1        115           3.00   \n",
       "..       ...        ...   ...                ...        ...            ...   \n",
       "133    12.70       3.55  2.36               21.5        106           1.70   \n",
       "137    12.53       5.51  2.64               25.0         96           1.79   \n",
       "72     13.49       1.66  2.24               24.0         87           1.88   \n",
       "140    12.93       2.81  2.70               21.0         96           1.54   \n",
       "37     13.05       1.65  2.55               18.0         98           2.45   \n",
       "\n",
       "     Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity   Hue  \\\n",
       "161        0.56                  0.50             0.80             5.88  0.96   \n",
       "117        2.09                  0.34             1.61             2.06  1.06   \n",
       "19         3.03                  0.17             1.66             5.10  0.96   \n",
       "69         1.28                  0.14             2.50             2.85  1.28   \n",
       "53         2.79                  0.39             1.68             6.30  1.13   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "133        1.20                  0.17             0.84             5.00  0.78   \n",
       "137        0.60                  0.63             1.10             5.00  0.82   \n",
       "72         1.84                  0.27             1.03             3.74  0.98   \n",
       "140        0.50                  0.53             0.75             4.60  0.77   \n",
       "37         2.43                  0.29             1.44             4.25  1.12   \n",
       "\n",
       "     0D280_0D315_of_diluted_wines  Proline  class  \n",
       "161                          1.82      680      3  \n",
       "117                          2.96      345      2  \n",
       "19                           3.36      845      1  \n",
       "69                           3.07      718      2  \n",
       "53                           2.93     1375      1  \n",
       "..                            ...      ...    ...  \n",
       "133                          1.29      600      3  \n",
       "137                          1.69      515      3  \n",
       "72                           2.78      472      2  \n",
       "140                          2.31      600      3  \n",
       "37                           2.51     1105      1  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_shuffled = dataset.sample(n=len(dataset), random_state=1)\n",
    "\n",
    "wine_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     1  2  3\n",
       "161  0  0  1\n",
       "117  0  1  0\n",
       "19   1  0  0\n",
       "69   0  1  0\n",
       "53   1  0  0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(wine_shuffled['class']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malicacid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity_of_ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>0D280_0D315_of_diluted_wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>13.69</td>\n",
       "      <td>3.26</td>\n",
       "      <td>2.54</td>\n",
       "      <td>20.0</td>\n",
       "      <td>107</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.80</td>\n",
       "      <td>5.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.82</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>12.42</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.19</td>\n",
       "      <td>22.5</td>\n",
       "      <td>108</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.06</td>\n",
       "      <td>1.06</td>\n",
       "      <td>2.96</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13.64</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.56</td>\n",
       "      <td>15.2</td>\n",
       "      <td>116</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.66</td>\n",
       "      <td>5.10</td>\n",
       "      <td>0.96</td>\n",
       "      <td>3.36</td>\n",
       "      <td>845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>12.21</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.75</td>\n",
       "      <td>16.8</td>\n",
       "      <td>151</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1.28</td>\n",
       "      <td>3.07</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>13.77</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.68</td>\n",
       "      <td>17.1</td>\n",
       "      <td>115</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.68</td>\n",
       "      <td>6.30</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2.93</td>\n",
       "      <td>1375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>12.70</td>\n",
       "      <td>3.55</td>\n",
       "      <td>2.36</td>\n",
       "      <td>21.5</td>\n",
       "      <td>106</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.84</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.29</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>12.53</td>\n",
       "      <td>5.51</td>\n",
       "      <td>2.64</td>\n",
       "      <td>25.0</td>\n",
       "      <td>96</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.10</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.69</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>13.49</td>\n",
       "      <td>1.66</td>\n",
       "      <td>2.24</td>\n",
       "      <td>24.0</td>\n",
       "      <td>87</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.98</td>\n",
       "      <td>2.78</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>12.93</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2.70</td>\n",
       "      <td>21.0</td>\n",
       "      <td>96</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.75</td>\n",
       "      <td>4.60</td>\n",
       "      <td>0.77</td>\n",
       "      <td>2.31</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>13.05</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2.55</td>\n",
       "      <td>18.0</td>\n",
       "      <td>98</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.44</td>\n",
       "      <td>4.25</td>\n",
       "      <td>1.12</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Alcohol  Malicacid   Ash  Alcalinity_of_ash  Magnesium  Total_phenols  \\\n",
       "161    13.69       3.26  2.54               20.0        107           1.83   \n",
       "117    12.42       1.61  2.19               22.5        108           2.00   \n",
       "19     13.64       3.10  2.56               15.2        116           2.70   \n",
       "69     12.21       1.19  1.75               16.8        151           1.85   \n",
       "53     13.77       1.90  2.68               17.1        115           3.00   \n",
       "..       ...        ...   ...                ...        ...            ...   \n",
       "133    12.70       3.55  2.36               21.5        106           1.70   \n",
       "137    12.53       5.51  2.64               25.0         96           1.79   \n",
       "72     13.49       1.66  2.24               24.0         87           1.88   \n",
       "140    12.93       2.81  2.70               21.0         96           1.54   \n",
       "37     13.05       1.65  2.55               18.0         98           2.45   \n",
       "\n",
       "     Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity   Hue  \\\n",
       "161        0.56                  0.50             0.80             5.88  0.96   \n",
       "117        2.09                  0.34             1.61             2.06  1.06   \n",
       "19         3.03                  0.17             1.66             5.10  0.96   \n",
       "69         1.28                  0.14             2.50             2.85  1.28   \n",
       "53         2.79                  0.39             1.68             6.30  1.13   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "133        1.20                  0.17             0.84             5.00  0.78   \n",
       "137        0.60                  0.63             1.10             5.00  0.82   \n",
       "72         1.84                  0.27             1.03             3.74  0.98   \n",
       "140        0.50                  0.53             0.75             4.60  0.77   \n",
       "37         2.43                  0.29             1.44             4.25  1.12   \n",
       "\n",
       "     0D280_0D315_of_diluted_wines  Proline  \n",
       "161                          1.82      680  \n",
       "117                          2.96      345  \n",
       "19                           3.36      845  \n",
       "69                           3.07      718  \n",
       "53                           2.93     1375  \n",
       "..                            ...      ...  \n",
       "133                          1.29      600  \n",
       "137                          1.69      515  \n",
       "72                           2.78      472  \n",
       "140                          2.31      600  \n",
       "37                           2.51     1105  \n",
       "\n",
       "[178 rows x 13 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_shuffled.drop('class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malicacid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity_of_ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>0D280_0D315_of_diluted_wines</th>\n",
       "      <th>Proline</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>13.69</td>\n",
       "      <td>3.26</td>\n",
       "      <td>2.54</td>\n",
       "      <td>20.0</td>\n",
       "      <td>107</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.80</td>\n",
       "      <td>5.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.82</td>\n",
       "      <td>680</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>12.42</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.19</td>\n",
       "      <td>22.5</td>\n",
       "      <td>108</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.06</td>\n",
       "      <td>1.06</td>\n",
       "      <td>2.96</td>\n",
       "      <td>345</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13.64</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.56</td>\n",
       "      <td>15.2</td>\n",
       "      <td>116</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.66</td>\n",
       "      <td>5.10</td>\n",
       "      <td>0.96</td>\n",
       "      <td>3.36</td>\n",
       "      <td>845</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>12.21</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.75</td>\n",
       "      <td>16.8</td>\n",
       "      <td>151</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1.28</td>\n",
       "      <td>3.07</td>\n",
       "      <td>718</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>13.77</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.68</td>\n",
       "      <td>17.1</td>\n",
       "      <td>115</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.68</td>\n",
       "      <td>6.30</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2.93</td>\n",
       "      <td>1375</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>12.70</td>\n",
       "      <td>3.55</td>\n",
       "      <td>2.36</td>\n",
       "      <td>21.5</td>\n",
       "      <td>106</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.84</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.29</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>12.53</td>\n",
       "      <td>5.51</td>\n",
       "      <td>2.64</td>\n",
       "      <td>25.0</td>\n",
       "      <td>96</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.10</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.69</td>\n",
       "      <td>515</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>13.49</td>\n",
       "      <td>1.66</td>\n",
       "      <td>2.24</td>\n",
       "      <td>24.0</td>\n",
       "      <td>87</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.98</td>\n",
       "      <td>2.78</td>\n",
       "      <td>472</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>12.93</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2.70</td>\n",
       "      <td>21.0</td>\n",
       "      <td>96</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.75</td>\n",
       "      <td>4.60</td>\n",
       "      <td>0.77</td>\n",
       "      <td>2.31</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>13.05</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2.55</td>\n",
       "      <td>18.0</td>\n",
       "      <td>98</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.44</td>\n",
       "      <td>4.25</td>\n",
       "      <td>1.12</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1105</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Alcohol  Malicacid   Ash  Alcalinity_of_ash  Magnesium  Total_phenols  \\\n",
       "161    13.69       3.26  2.54               20.0        107           1.83   \n",
       "117    12.42       1.61  2.19               22.5        108           2.00   \n",
       "19     13.64       3.10  2.56               15.2        116           2.70   \n",
       "69     12.21       1.19  1.75               16.8        151           1.85   \n",
       "53     13.77       1.90  2.68               17.1        115           3.00   \n",
       "..       ...        ...   ...                ...        ...            ...   \n",
       "133    12.70       3.55  2.36               21.5        106           1.70   \n",
       "137    12.53       5.51  2.64               25.0         96           1.79   \n",
       "72     13.49       1.66  2.24               24.0         87           1.88   \n",
       "140    12.93       2.81  2.70               21.0         96           1.54   \n",
       "37     13.05       1.65  2.55               18.0         98           2.45   \n",
       "\n",
       "     Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity   Hue  \\\n",
       "161        0.56                  0.50             0.80             5.88  0.96   \n",
       "117        2.09                  0.34             1.61             2.06  1.06   \n",
       "19         3.03                  0.17             1.66             5.10  0.96   \n",
       "69         1.28                  0.14             2.50             2.85  1.28   \n",
       "53         2.79                  0.39             1.68             6.30  1.13   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "133        1.20                  0.17             0.84             5.00  0.78   \n",
       "137        0.60                  0.63             1.10             5.00  0.82   \n",
       "72         1.84                  0.27             1.03             3.74  0.98   \n",
       "140        0.50                  0.53             0.75             4.60  0.77   \n",
       "37         2.43                  0.29             1.44             4.25  1.12   \n",
       "\n",
       "     0D280_0D315_of_diluted_wines  Proline  1  2  3  \n",
       "161                          1.82      680  0  0  1  \n",
       "117                          2.96      345  0  1  0  \n",
       "19                           3.36      845  1  0  0  \n",
       "69                           3.07      718  0  1  0  \n",
       "53                           2.93     1375  1  0  0  \n",
       "..                            ...      ... .. .. ..  \n",
       "133                          1.29      600  0  0  1  \n",
       "137                          1.69      515  0  0  1  \n",
       "72                           2.78      472  0  1  0  \n",
       "140                          2.31      600  0  0  1  \n",
       "37                           2.51     1105  1  0  0  \n",
       "\n",
       "[178 rows x 16 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_list = pd.concat([wine_shuffled.drop('class', axis=1), pd.get_dummies(wine_shuffled['class'])], axis=1)\n",
    "\n",
    "wine_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malicacid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity_of_ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_phenols</th>\n",
       "      <th>Nonflavanoid_phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>0D280_0D315_of_diluted_wines</th>\n",
       "      <th>Proline</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>Flavanoids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>13.69</td>\n",
       "      <td>3.26</td>\n",
       "      <td>2.54</td>\n",
       "      <td>20.0</td>\n",
       "      <td>107</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.80</td>\n",
       "      <td>5.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.82</td>\n",
       "      <td>680</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>12.42</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.19</td>\n",
       "      <td>22.5</td>\n",
       "      <td>108</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.06</td>\n",
       "      <td>1.06</td>\n",
       "      <td>2.96</td>\n",
       "      <td>345</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13.64</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.56</td>\n",
       "      <td>15.2</td>\n",
       "      <td>116</td>\n",
       "      <td>2.70</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.66</td>\n",
       "      <td>5.10</td>\n",
       "      <td>0.96</td>\n",
       "      <td>3.36</td>\n",
       "      <td>845</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>12.21</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.75</td>\n",
       "      <td>16.8</td>\n",
       "      <td>151</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1.28</td>\n",
       "      <td>3.07</td>\n",
       "      <td>718</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>13.77</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.68</td>\n",
       "      <td>17.1</td>\n",
       "      <td>115</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.68</td>\n",
       "      <td>6.30</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2.93</td>\n",
       "      <td>1375</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>12.70</td>\n",
       "      <td>3.55</td>\n",
       "      <td>2.36</td>\n",
       "      <td>21.5</td>\n",
       "      <td>106</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.84</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.29</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>12.53</td>\n",
       "      <td>5.51</td>\n",
       "      <td>2.64</td>\n",
       "      <td>25.0</td>\n",
       "      <td>96</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.10</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.69</td>\n",
       "      <td>515</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>13.49</td>\n",
       "      <td>1.66</td>\n",
       "      <td>2.24</td>\n",
       "      <td>24.0</td>\n",
       "      <td>87</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.98</td>\n",
       "      <td>2.78</td>\n",
       "      <td>472</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>12.93</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2.70</td>\n",
       "      <td>21.0</td>\n",
       "      <td>96</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.75</td>\n",
       "      <td>4.60</td>\n",
       "      <td>0.77</td>\n",
       "      <td>2.31</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>13.05</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2.55</td>\n",
       "      <td>18.0</td>\n",
       "      <td>98</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.44</td>\n",
       "      <td>4.25</td>\n",
       "      <td>1.12</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1105</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Alcohol  Malicacid   Ash  Alcalinity_of_ash  Magnesium  Total_phenols  \\\n",
       "161    13.69       3.26  2.54               20.0        107           1.83   \n",
       "117    12.42       1.61  2.19               22.5        108           2.00   \n",
       "19     13.64       3.10  2.56               15.2        116           2.70   \n",
       "69     12.21       1.19  1.75               16.8        151           1.85   \n",
       "53     13.77       1.90  2.68               17.1        115           3.00   \n",
       "..       ...        ...   ...                ...        ...            ...   \n",
       "133    12.70       3.55  2.36               21.5        106           1.70   \n",
       "137    12.53       5.51  2.64               25.0         96           1.79   \n",
       "72     13.49       1.66  2.24               24.0         87           1.88   \n",
       "140    12.93       2.81  2.70               21.0         96           1.54   \n",
       "37     13.05       1.65  2.55               18.0         98           2.45   \n",
       "\n",
       "     Nonflavanoid_phenols  Proanthocyanins  Color_intensity   Hue  \\\n",
       "161                  0.50             0.80             5.88  0.96   \n",
       "117                  0.34             1.61             2.06  1.06   \n",
       "19                   0.17             1.66             5.10  0.96   \n",
       "69                   0.14             2.50             2.85  1.28   \n",
       "53                   0.39             1.68             6.30  1.13   \n",
       "..                    ...              ...              ...   ...   \n",
       "133                  0.17             0.84             5.00  0.78   \n",
       "137                  0.63             1.10             5.00  0.82   \n",
       "72                   0.27             1.03             3.74  0.98   \n",
       "140                  0.53             0.75             4.60  0.77   \n",
       "37                   0.29             1.44             4.25  1.12   \n",
       "\n",
       "     0D280_0D315_of_diluted_wines  Proline  1  2  3  Flavanoids  \n",
       "161                          1.82      680  0  0  1        0.56  \n",
       "117                          2.96      345  0  1  0        2.09  \n",
       "19                           3.36      845  1  0  0        3.03  \n",
       "69                           3.07      718  0  1  0        1.28  \n",
       "53                           2.93     1375  1  0  0        2.79  \n",
       "..                            ...      ... .. .. ..         ...  \n",
       "133                          1.29      600  0  0  1        1.20  \n",
       "137                          1.69      515  0  0  1        0.60  \n",
       "72                           2.78      472  0  1  0        1.84  \n",
       "140                          2.31      600  0  0  1        0.50  \n",
       "37                           2.51     1105  1  0  0        2.43  \n",
       "\n",
       "[178 rows x 16 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_list = wine_list[['Alcohol','Malicacid','Ash','Alcalinity_of_ash',\n",
    "                       'Magnesium','Total_phenols','Nonflavanoid_phenols',\n",
    "                       'Proanthocyanins','Color_intensity','Hue','0D280_0D315_of_diluted_wines',\n",
    "                       'Proline',1,2,3, \n",
    "                       'Flavanoids',]]\n",
    "\n",
    "wine_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_list.rename(columns={1: '1', 2: '2', 3: '3'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malicacid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity_of_ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_phenols</th>\n",
       "      <th>Nonflavanoid_phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>0D280_0D315_of_diluted_wines</th>\n",
       "      <th>Proline</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>Flavanoids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alcohol</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.094397</td>\n",
       "      <td>0.211545</td>\n",
       "      <td>-0.310235</td>\n",
       "      <td>0.270798</td>\n",
       "      <td>0.289101</td>\n",
       "      <td>-0.155929</td>\n",
       "      <td>0.136698</td>\n",
       "      <td>0.546364</td>\n",
       "      <td>-0.071747</td>\n",
       "      <td>0.072343</td>\n",
       "      <td>0.643720</td>\n",
       "      <td>0.647232</td>\n",
       "      <td>-0.726383</td>\n",
       "      <td>0.114941</td>\n",
       "      <td>0.236815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malicacid</th>\n",
       "      <td>0.094397</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.164045</td>\n",
       "      <td>0.288500</td>\n",
       "      <td>-0.054575</td>\n",
       "      <td>-0.335167</td>\n",
       "      <td>0.292977</td>\n",
       "      <td>-0.220746</td>\n",
       "      <td>0.248985</td>\n",
       "      <td>-0.561296</td>\n",
       "      <td>-0.368710</td>\n",
       "      <td>-0.192011</td>\n",
       "      <td>-0.205847</td>\n",
       "      <td>-0.295175</td>\n",
       "      <td>0.544042</td>\n",
       "      <td>-0.411007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ash</th>\n",
       "      <td>0.211545</td>\n",
       "      <td>0.164045</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.443367</td>\n",
       "      <td>0.286587</td>\n",
       "      <td>0.128980</td>\n",
       "      <td>0.186230</td>\n",
       "      <td>0.009652</td>\n",
       "      <td>0.258887</td>\n",
       "      <td>-0.074667</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>0.223626</td>\n",
       "      <td>0.229268</td>\n",
       "      <td>-0.362457</td>\n",
       "      <td>0.156738</td>\n",
       "      <td>0.115077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcalinity_of_ash</th>\n",
       "      <td>-0.310235</td>\n",
       "      <td>0.288500</td>\n",
       "      <td>0.443367</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-0.321113</td>\n",
       "      <td>0.361922</td>\n",
       "      <td>-0.197327</td>\n",
       "      <td>0.018732</td>\n",
       "      <td>-0.273955</td>\n",
       "      <td>-0.276769</td>\n",
       "      <td>-0.440597</td>\n",
       "      <td>-0.519646</td>\n",
       "      <td>0.181764</td>\n",
       "      <td>0.350650</td>\n",
       "      <td>-0.351370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Magnesium</th>\n",
       "      <td>0.270798</td>\n",
       "      <td>-0.054575</td>\n",
       "      <td>0.286587</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.214401</td>\n",
       "      <td>-0.256294</td>\n",
       "      <td>0.236441</td>\n",
       "      <td>0.199950</td>\n",
       "      <td>0.055398</td>\n",
       "      <td>0.066004</td>\n",
       "      <td>0.393351</td>\n",
       "      <td>0.326171</td>\n",
       "      <td>-0.296972</td>\n",
       "      <td>-0.018306</td>\n",
       "      <td>0.195784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_phenols</th>\n",
       "      <td>0.289101</td>\n",
       "      <td>-0.335167</td>\n",
       "      <td>0.128980</td>\n",
       "      <td>-0.321113</td>\n",
       "      <td>0.214401</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.449935</td>\n",
       "      <td>0.612413</td>\n",
       "      <td>-0.055136</td>\n",
       "      <td>0.433681</td>\n",
       "      <td>0.699949</td>\n",
       "      <td>0.498115</td>\n",
       "      <td>0.614960</td>\n",
       "      <td>-0.047301</td>\n",
       "      <td>-0.600119</td>\n",
       "      <td>0.864564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nonflavanoid_phenols</th>\n",
       "      <td>-0.155929</td>\n",
       "      <td>0.292977</td>\n",
       "      <td>0.186230</td>\n",
       "      <td>0.361922</td>\n",
       "      <td>-0.256294</td>\n",
       "      <td>-0.449935</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.365845</td>\n",
       "      <td>0.139057</td>\n",
       "      <td>-0.262640</td>\n",
       "      <td>-0.503270</td>\n",
       "      <td>-0.311385</td>\n",
       "      <td>-0.407680</td>\n",
       "      <td>0.011868</td>\n",
       "      <td>0.419347</td>\n",
       "      <td>-0.537900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <td>0.136698</td>\n",
       "      <td>-0.220746</td>\n",
       "      <td>0.009652</td>\n",
       "      <td>-0.197327</td>\n",
       "      <td>0.236441</td>\n",
       "      <td>0.612413</td>\n",
       "      <td>-0.365845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.025250</td>\n",
       "      <td>0.295544</td>\n",
       "      <td>0.519067</td>\n",
       "      <td>0.330417</td>\n",
       "      <td>0.380500</td>\n",
       "      <td>0.056208</td>\n",
       "      <td>-0.465629</td>\n",
       "      <td>0.652692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Color_intensity</th>\n",
       "      <td>0.546364</td>\n",
       "      <td>0.248985</td>\n",
       "      <td>0.258887</td>\n",
       "      <td>0.018732</td>\n",
       "      <td>0.199950</td>\n",
       "      <td>-0.055136</td>\n",
       "      <td>0.139057</td>\n",
       "      <td>-0.025250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.521813</td>\n",
       "      <td>-0.428815</td>\n",
       "      <td>0.316100</td>\n",
       "      <td>0.143221</td>\n",
       "      <td>-0.694679</td>\n",
       "      <td>0.614582</td>\n",
       "      <td>-0.172379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hue</th>\n",
       "      <td>-0.071747</td>\n",
       "      <td>-0.561296</td>\n",
       "      <td>-0.074667</td>\n",
       "      <td>-0.273955</td>\n",
       "      <td>0.055398</td>\n",
       "      <td>0.433681</td>\n",
       "      <td>-0.262640</td>\n",
       "      <td>0.295544</td>\n",
       "      <td>-0.521813</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.565468</td>\n",
       "      <td>0.236183</td>\n",
       "      <td>0.323088</td>\n",
       "      <td>0.353213</td>\n",
       "      <td>-0.732443</td>\n",
       "      <td>0.543479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0D280_0D315_of_diluted_wines</th>\n",
       "      <td>0.072343</td>\n",
       "      <td>-0.368710</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>-0.276769</td>\n",
       "      <td>0.066004</td>\n",
       "      <td>0.699949</td>\n",
       "      <td>-0.503270</td>\n",
       "      <td>0.519067</td>\n",
       "      <td>-0.428815</td>\n",
       "      <td>0.565468</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.312761</td>\n",
       "      <td>0.543131</td>\n",
       "      <td>0.199813</td>\n",
       "      <td>-0.796590</td>\n",
       "      <td>0.787194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proline</th>\n",
       "      <td>0.643720</td>\n",
       "      <td>-0.192011</td>\n",
       "      <td>0.223626</td>\n",
       "      <td>-0.440597</td>\n",
       "      <td>0.393351</td>\n",
       "      <td>0.498115</td>\n",
       "      <td>-0.311385</td>\n",
       "      <td>0.330417</td>\n",
       "      <td>0.316100</td>\n",
       "      <td>0.236183</td>\n",
       "      <td>0.312761</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.827000</td>\n",
       "      <td>-0.589850</td>\n",
       "      <td>-0.226394</td>\n",
       "      <td>0.494193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.647232</td>\n",
       "      <td>-0.205847</td>\n",
       "      <td>0.229268</td>\n",
       "      <td>-0.519646</td>\n",
       "      <td>0.326171</td>\n",
       "      <td>0.614960</td>\n",
       "      <td>-0.407680</td>\n",
       "      <td>0.380500</td>\n",
       "      <td>0.143221</td>\n",
       "      <td>0.323088</td>\n",
       "      <td>0.543131</td>\n",
       "      <td>0.827000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.573574</td>\n",
       "      <td>-0.427860</td>\n",
       "      <td>0.673770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.726383</td>\n",
       "      <td>-0.295175</td>\n",
       "      <td>-0.362457</td>\n",
       "      <td>0.181764</td>\n",
       "      <td>-0.296972</td>\n",
       "      <td>-0.047301</td>\n",
       "      <td>0.011868</td>\n",
       "      <td>0.056208</td>\n",
       "      <td>-0.694679</td>\n",
       "      <td>0.353213</td>\n",
       "      <td>0.199813</td>\n",
       "      <td>-0.589850</td>\n",
       "      <td>-0.573574</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.494978</td>\n",
       "      <td>0.042179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.114941</td>\n",
       "      <td>0.544042</td>\n",
       "      <td>0.156738</td>\n",
       "      <td>0.350650</td>\n",
       "      <td>-0.018306</td>\n",
       "      <td>-0.600119</td>\n",
       "      <td>0.419347</td>\n",
       "      <td>-0.465629</td>\n",
       "      <td>0.614582</td>\n",
       "      <td>-0.732443</td>\n",
       "      <td>-0.796590</td>\n",
       "      <td>-0.226394</td>\n",
       "      <td>-0.427860</td>\n",
       "      <td>-0.494978</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.761232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flavanoids</th>\n",
       "      <td>0.236815</td>\n",
       "      <td>-0.411007</td>\n",
       "      <td>0.115077</td>\n",
       "      <td>-0.351370</td>\n",
       "      <td>0.195784</td>\n",
       "      <td>0.864564</td>\n",
       "      <td>-0.537900</td>\n",
       "      <td>0.652692</td>\n",
       "      <td>-0.172379</td>\n",
       "      <td>0.543479</td>\n",
       "      <td>0.787194</td>\n",
       "      <td>0.494193</td>\n",
       "      <td>0.673770</td>\n",
       "      <td>0.042179</td>\n",
       "      <td>-0.761232</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Alcohol  Malicacid       Ash  \\\n",
       "Alcohol                       1.000000   0.094397  0.211545   \n",
       "Malicacid                     0.094397   1.000000  0.164045   \n",
       "Ash                           0.211545   0.164045  1.000000   \n",
       "Alcalinity_of_ash            -0.310235   0.288500  0.443367   \n",
       "Magnesium                     0.270798  -0.054575  0.286587   \n",
       "Total_phenols                 0.289101  -0.335167  0.128980   \n",
       "Nonflavanoid_phenols         -0.155929   0.292977  0.186230   \n",
       "Proanthocyanins               0.136698  -0.220746  0.009652   \n",
       "Color_intensity               0.546364   0.248985  0.258887   \n",
       "Hue                          -0.071747  -0.561296 -0.074667   \n",
       "0D280_0D315_of_diluted_wines  0.072343  -0.368710  0.003911   \n",
       "Proline                       0.643720  -0.192011  0.223626   \n",
       "1                             0.647232  -0.205847  0.229268   \n",
       "2                            -0.726383  -0.295175 -0.362457   \n",
       "3                             0.114941   0.544042  0.156738   \n",
       "Flavanoids                    0.236815  -0.411007  0.115077   \n",
       "\n",
       "                              Alcalinity_of_ash  Magnesium  Total_phenols  \\\n",
       "Alcohol                               -0.310235   0.270798       0.289101   \n",
       "Malicacid                              0.288500  -0.054575      -0.335167   \n",
       "Ash                                    0.443367   0.286587       0.128980   \n",
       "Alcalinity_of_ash                      1.000000  -0.083333      -0.321113   \n",
       "Magnesium                             -0.083333   1.000000       0.214401   \n",
       "Total_phenols                         -0.321113   0.214401       1.000000   \n",
       "Nonflavanoid_phenols                   0.361922  -0.256294      -0.449935   \n",
       "Proanthocyanins                       -0.197327   0.236441       0.612413   \n",
       "Color_intensity                        0.018732   0.199950      -0.055136   \n",
       "Hue                                   -0.273955   0.055398       0.433681   \n",
       "0D280_0D315_of_diluted_wines          -0.276769   0.066004       0.699949   \n",
       "Proline                               -0.440597   0.393351       0.498115   \n",
       "1                                     -0.519646   0.326171       0.614960   \n",
       "2                                      0.181764  -0.296972      -0.047301   \n",
       "3                                      0.350650  -0.018306      -0.600119   \n",
       "Flavanoids                            -0.351370   0.195784       0.864564   \n",
       "\n",
       "                              Nonflavanoid_phenols  Proanthocyanins  \\\n",
       "Alcohol                                  -0.155929         0.136698   \n",
       "Malicacid                                 0.292977        -0.220746   \n",
       "Ash                                       0.186230         0.009652   \n",
       "Alcalinity_of_ash                         0.361922        -0.197327   \n",
       "Magnesium                                -0.256294         0.236441   \n",
       "Total_phenols                            -0.449935         0.612413   \n",
       "Nonflavanoid_phenols                      1.000000        -0.365845   \n",
       "Proanthocyanins                          -0.365845         1.000000   \n",
       "Color_intensity                           0.139057        -0.025250   \n",
       "Hue                                      -0.262640         0.295544   \n",
       "0D280_0D315_of_diluted_wines             -0.503270         0.519067   \n",
       "Proline                                  -0.311385         0.330417   \n",
       "1                                        -0.407680         0.380500   \n",
       "2                                         0.011868         0.056208   \n",
       "3                                         0.419347        -0.465629   \n",
       "Flavanoids                               -0.537900         0.652692   \n",
       "\n",
       "                              Color_intensity       Hue  \\\n",
       "Alcohol                              0.546364 -0.071747   \n",
       "Malicacid                            0.248985 -0.561296   \n",
       "Ash                                  0.258887 -0.074667   \n",
       "Alcalinity_of_ash                    0.018732 -0.273955   \n",
       "Magnesium                            0.199950  0.055398   \n",
       "Total_phenols                       -0.055136  0.433681   \n",
       "Nonflavanoid_phenols                 0.139057 -0.262640   \n",
       "Proanthocyanins                     -0.025250  0.295544   \n",
       "Color_intensity                      1.000000 -0.521813   \n",
       "Hue                                 -0.521813  1.000000   \n",
       "0D280_0D315_of_diluted_wines        -0.428815  0.565468   \n",
       "Proline                              0.316100  0.236183   \n",
       "1                                    0.143221  0.323088   \n",
       "2                                   -0.694679  0.353213   \n",
       "3                                    0.614582 -0.732443   \n",
       "Flavanoids                          -0.172379  0.543479   \n",
       "\n",
       "                              0D280_0D315_of_diluted_wines   Proline  \\\n",
       "Alcohol                                           0.072343  0.643720   \n",
       "Malicacid                                        -0.368710 -0.192011   \n",
       "Ash                                               0.003911  0.223626   \n",
       "Alcalinity_of_ash                                -0.276769 -0.440597   \n",
       "Magnesium                                         0.066004  0.393351   \n",
       "Total_phenols                                     0.699949  0.498115   \n",
       "Nonflavanoid_phenols                             -0.503270 -0.311385   \n",
       "Proanthocyanins                                   0.519067  0.330417   \n",
       "Color_intensity                                  -0.428815  0.316100   \n",
       "Hue                                               0.565468  0.236183   \n",
       "0D280_0D315_of_diluted_wines                      1.000000  0.312761   \n",
       "Proline                                           0.312761  1.000000   \n",
       "1                                                 0.543131  0.827000   \n",
       "2                                                 0.199813 -0.589850   \n",
       "3                                                -0.796590 -0.226394   \n",
       "Flavanoids                                        0.787194  0.494193   \n",
       "\n",
       "                                     1         2         3  Flavanoids  \n",
       "Alcohol                       0.647232 -0.726383  0.114941    0.236815  \n",
       "Malicacid                    -0.205847 -0.295175  0.544042   -0.411007  \n",
       "Ash                           0.229268 -0.362457  0.156738    0.115077  \n",
       "Alcalinity_of_ash            -0.519646  0.181764  0.350650   -0.351370  \n",
       "Magnesium                     0.326171 -0.296972 -0.018306    0.195784  \n",
       "Total_phenols                 0.614960 -0.047301 -0.600119    0.864564  \n",
       "Nonflavanoid_phenols         -0.407680  0.011868  0.419347   -0.537900  \n",
       "Proanthocyanins               0.380500  0.056208 -0.465629    0.652692  \n",
       "Color_intensity               0.143221 -0.694679  0.614582   -0.172379  \n",
       "Hue                           0.323088  0.353213 -0.732443    0.543479  \n",
       "0D280_0D315_of_diluted_wines  0.543131  0.199813 -0.796590    0.787194  \n",
       "Proline                       0.827000 -0.589850 -0.226394    0.494193  \n",
       "1                             1.000000 -0.573574 -0.427860    0.673770  \n",
       "2                            -0.573574  1.000000 -0.494978    0.042179  \n",
       "3                            -0.427860 -0.494978  1.000000   -0.761232  \n",
       "Flavanoids                    0.673770  0.042179 -0.761232    1.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_list.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTIVE_FEATURES = ['Alcohol','Malicacid','Ash','Alcalinity_of_ash',\n",
    "                       'Magnesium','Total_phenols','Nonflavanoid_phenols',\n",
    "                       'Proanthocyanins','Color_intensity','Hue','0D280_0D315_of_diluted_wines',\n",
    "                       'Proline','1','2','3']\n",
    "TARGET = 'Flavanoids'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = wine_list.values[:,:-1], wine_list.values[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function from David to reduce features based on correlation\n",
    "def corr_calc(df, target='', x=''):\n",
    "    corr = df.corr()[target].abs() > x\n",
    "    features=[]\n",
    "    for i in corr.index:\n",
    "        if corr[i] == True:\n",
    "            features.append(i)\n",
    "    features.pop(features.index(target))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alcohol',\n",
       " 'Malicacid',\n",
       " 'Alcalinity_of_ash',\n",
       " 'Total_phenols',\n",
       " 'Nonflavanoid_phenols',\n",
       " 'Proanthocyanins',\n",
       " 'Hue',\n",
       " '0D280_0D315_of_diluted_wines',\n",
       " 'Proline',\n",
       " '1',\n",
       " '3']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = corr_calc(wine_list, TARGET, x=0.2)\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3177205740764004, 0.32345234829227204)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "lm = LinearRegression().fit(X_train, y_train)\n",
    "mse(lm.predict(X_train), y_train, squared=False), mse(lm.predict(X), y, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5321973119748346, 0.5617913763683079)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=2).fit(X_train, y_train)\n",
    "mse(knn.predict(X_train), y_train, squared=False), mse(knn.predict(X), y, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.14423832078471469, 0.1952640311347703)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr = RandomForestRegressor(max_depth=12).fit(X_train, y_train)\n",
    "mse(rfr.predict(X_train), y_train, squared=False), mse(rfr.predict(X), y, squared=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.16056936972785033, 0.1968213580284825)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbr = GradientBoostingRegressor(n_estimators=30).fit(X_train, y_train)\n",
    "mse(gbr.predict(X_train), y_train, squared=False), mse(gbr.predict(X), y, squared=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 31138.6406 - root_mean_squared_error: 176.4614WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "WARNING:tensorflow:From c:\\Users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From c:\\Users\\dmm46\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 8202.6982 - root_mean_squared_error: 90.5687 - val_loss: 6.7206 - val_root_mean_squared_error: 2.5924\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 7.1912 - root_mean_squared_error: 2.6816 - val_loss: 7.4751 - val_root_mean_squared_error: 2.7341\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 7.8148 - root_mean_squared_error: 2.7955 - val_loss: 7.8465 - val_root_mean_squared_error: 2.8012\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 8.0992 - root_mean_squared_error: 2.8459 - val_loss: 7.9913 - val_root_mean_squared_error: 2.8269\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 8.1888 - root_mean_squared_error: 2.8616 - val_loss: 7.9894 - val_root_mean_squared_error: 2.8266\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 8.1497 - root_mean_squared_error: 2.8548 - val_loss: 7.8916 - val_root_mean_squared_error: 2.8092\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 8.0263 - root_mean_squared_error: 2.8331 - val_loss: 7.7299 - val_root_mean_squared_error: 2.7803\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 7.8474 - root_mean_squared_error: 2.8013 - val_loss: 7.5245 - val_root_mean_squared_error: 2.7431\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.6261 - root_mean_squared_error: 2.7615 - val_loss: 7.2939 - val_root_mean_squared_error: 2.7007\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 7.3874 - root_mean_squared_error: 2.7180 - val_loss: 7.0453 - val_root_mean_squared_error: 2.6543\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 7.1293 - root_mean_squared_error: 2.6701 - val_loss: 6.7870 - val_root_mean_squared_error: 2.6052\n",
      "Epoch 12/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.8734 - root_mean_squared_error: 2.8060INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 6.8685 - root_mean_squared_error: 2.6208 - val_loss: 6.5200 - val_root_mean_squared_error: 2.5534\n",
      "Epoch 13/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.0439 - root_mean_squared_error: 2.8362INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 6.6017 - root_mean_squared_error: 2.5694 - val_loss: 6.2525 - val_root_mean_squared_error: 2.5005\n",
      "Epoch 14/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.7927 - root_mean_squared_error: 2.4068INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 6.3261 - root_mean_squared_error: 2.5152 - val_loss: 5.9902 - val_root_mean_squared_error: 2.4475\n",
      "Epoch 15/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.0822 - root_mean_squared_error: 2.4662INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 6.0618 - root_mean_squared_error: 2.4621 - val_loss: 5.7302 - val_root_mean_squared_error: 2.3938\n",
      "Epoch 16/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.0590 - root_mean_squared_error: 2.6569INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 5.8003 - root_mean_squared_error: 2.4084 - val_loss: 5.4731 - val_root_mean_squared_error: 2.3395\n",
      "Epoch 17/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.7128 - root_mean_squared_error: 2.3901INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 5.5425 - root_mean_squared_error: 2.3543 - val_loss: 5.2204 - val_root_mean_squared_error: 2.2848\n",
      "Epoch 18/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.2419 - root_mean_squared_error: 2.4984INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 5.2855 - root_mean_squared_error: 2.2990 - val_loss: 4.9772 - val_root_mean_squared_error: 2.2310\n",
      "Epoch 19/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.1778 - root_mean_squared_error: 2.2755INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 5.0424 - root_mean_squared_error: 2.2455 - val_loss: 4.7402 - val_root_mean_squared_error: 2.1772\n",
      "Epoch 20/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.1633 - root_mean_squared_error: 2.4826INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 4.8059 - root_mean_squared_error: 2.1922 - val_loss: 4.5097 - val_root_mean_squared_error: 2.1236\n",
      "Epoch 21/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.4674 - root_mean_squared_error: 2.1136INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 4.5690 - root_mean_squared_error: 2.1375 - val_loss: 4.2899 - val_root_mean_squared_error: 2.0712\n",
      "Epoch 22/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.9107 - root_mean_squared_error: 2.2160INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 4.3523 - root_mean_squared_error: 2.0862 - val_loss: 4.0758 - val_root_mean_squared_error: 2.0189\n",
      "Epoch 23/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.1756 - root_mean_squared_error: 2.2750INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 4.1380 - root_mean_squared_error: 2.0342 - val_loss: 3.8706 - val_root_mean_squared_error: 1.9674\n",
      "Epoch 24/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.9661 - root_mean_squared_error: 1.9915INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 3.9334 - root_mean_squared_error: 1.9833 - val_loss: 3.6746 - val_root_mean_squared_error: 1.9169\n",
      "Epoch 25/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.7166 - root_mean_squared_error: 1.9278INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 3.7335 - root_mean_squared_error: 1.9322 - val_loss: 3.4886 - val_root_mean_squared_error: 1.8678\n",
      "Epoch 26/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.5693 - root_mean_squared_error: 1.8892INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 3.5488 - root_mean_squared_error: 1.8838 - val_loss: 3.3109 - val_root_mean_squared_error: 1.8196\n",
      "Epoch 27/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.9273 - root_mean_squared_error: 1.9817INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 3.3680 - root_mean_squared_error: 1.8352 - val_loss: 3.1432 - val_root_mean_squared_error: 1.7729\n",
      "Epoch 28/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.7305 - root_mean_squared_error: 1.6524INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 3.1957 - root_mean_squared_error: 1.7877 - val_loss: 2.9819 - val_root_mean_squared_error: 1.7268\n",
      "Epoch 29/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.9565 - root_mean_squared_error: 1.7194INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 3.0347 - root_mean_squared_error: 1.7420 - val_loss: 2.8271 - val_root_mean_squared_error: 1.6814\n",
      "Epoch 30/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4126 - root_mean_squared_error: 1.5533INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 2.8822 - root_mean_squared_error: 1.6977 - val_loss: 2.6812 - val_root_mean_squared_error: 1.6374\n",
      "Epoch 31/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.0224 - root_mean_squared_error: 1.7385INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 2.7366 - root_mean_squared_error: 1.6543 - val_loss: 2.5461 - val_root_mean_squared_error: 1.5956\n",
      "Epoch 32/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.7494 - root_mean_squared_error: 1.6581INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 2.6000 - root_mean_squared_error: 1.6124 - val_loss: 2.4203 - val_root_mean_squared_error: 1.5557\n",
      "Epoch 33/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9684 - root_mean_squared_error: 1.4030INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 2.4735 - root_mean_squared_error: 1.5727 - val_loss: 2.3023 - val_root_mean_squared_error: 1.5173\n",
      "Epoch 34/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1834 - root_mean_squared_error: 1.4776INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 2.3529 - root_mean_squared_error: 1.5339 - val_loss: 2.1933 - val_root_mean_squared_error: 1.4810\n",
      "Epoch 35/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5880 - root_mean_squared_error: 1.6087INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 2.2467 - root_mean_squared_error: 1.4989 - val_loss: 2.0894 - val_root_mean_squared_error: 1.4455\n",
      "Epoch 36/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0586 - root_mean_squared_error: 1.4348INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 2.1403 - root_mean_squared_error: 1.4630 - val_loss: 1.9945 - val_root_mean_squared_error: 1.4123\n",
      "Epoch 37/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.9915 - root_mean_squared_error: 1.7296INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 2.0470 - root_mean_squared_error: 1.4307 - val_loss: 1.9058 - val_root_mean_squared_error: 1.3805\n",
      "Epoch 38/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4603 - root_mean_squared_error: 1.5685INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 1.9592 - root_mean_squared_error: 1.3997 - val_loss: 1.8233 - val_root_mean_squared_error: 1.3503\n",
      "Epoch 39/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6866 - root_mean_squared_error: 1.2987INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 1.8723 - root_mean_squared_error: 1.3683 - val_loss: 1.7485 - val_root_mean_squared_error: 1.3223\n",
      "Epoch 40/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4399 - root_mean_squared_error: 1.5620INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 1.8006 - root_mean_squared_error: 1.3419 - val_loss: 1.6770 - val_root_mean_squared_error: 1.2950\n",
      "Epoch 41/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9127 - root_mean_squared_error: 1.3830INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 1.7259 - root_mean_squared_error: 1.3137 - val_loss: 1.6119 - val_root_mean_squared_error: 1.2696\n",
      "Epoch 42/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4140 - root_mean_squared_error: 1.1891INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 1.6596 - root_mean_squared_error: 1.2882 - val_loss: 1.5514 - val_root_mean_squared_error: 1.2456\n",
      "Epoch 43/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3168 - root_mean_squared_error: 1.1475INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 1.5992 - root_mean_squared_error: 1.2646 - val_loss: 1.4956 - val_root_mean_squared_error: 1.2229\n",
      "Epoch 44/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7427 - root_mean_squared_error: 1.3201INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 1.5431 - root_mean_squared_error: 1.2422 - val_loss: 1.4453 - val_root_mean_squared_error: 1.2022\n",
      "Epoch 45/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5512 - root_mean_squared_error: 1.2455INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 1.4921 - root_mean_squared_error: 1.2215 - val_loss: 1.3989 - val_root_mean_squared_error: 1.1828\n",
      "Epoch 46/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4698 - root_mean_squared_error: 1.2124INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 1.4446 - root_mean_squared_error: 1.2019 - val_loss: 1.3574 - val_root_mean_squared_error: 1.1651\n",
      "Epoch 47/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1504 - root_mean_squared_error: 1.0726INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 1.4026 - root_mean_squared_error: 1.1843 - val_loss: 1.3196 - val_root_mean_squared_error: 1.1487\n",
      "Epoch 48/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2567 - root_mean_squared_error: 1.1210INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 1.3645 - root_mean_squared_error: 1.1681 - val_loss: 1.2851 - val_root_mean_squared_error: 1.1336\n",
      "Epoch 49/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3583 - root_mean_squared_error: 1.1655INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 1.3307 - root_mean_squared_error: 1.1536 - val_loss: 1.2541 - val_root_mean_squared_error: 1.1199\n",
      "Epoch 50/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1676 - root_mean_squared_error: 1.0806INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 1.2978 - root_mean_squared_error: 1.1392 - val_loss: 1.2264 - val_root_mean_squared_error: 1.1074\n",
      "Epoch 51/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3479 - root_mean_squared_error: 1.1610INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 1.2664 - root_mean_squared_error: 1.1254 - val_loss: 1.2014 - val_root_mean_squared_error: 1.0961\n",
      "Epoch 52/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0805 - root_mean_squared_error: 1.0395INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 1.2414 - root_mean_squared_error: 1.1142 - val_loss: 1.1773 - val_root_mean_squared_error: 1.0850\n",
      "Epoch 53/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3451 - root_mean_squared_error: 1.1598INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 1.2177 - root_mean_squared_error: 1.1035 - val_loss: 1.1550 - val_root_mean_squared_error: 1.0747\n",
      "Epoch 54/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2784 - root_mean_squared_error: 1.1307INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 1.1933 - root_mean_squared_error: 1.0924 - val_loss: 1.1359 - val_root_mean_squared_error: 1.0658\n",
      "Epoch 55/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1887 - root_mean_squared_error: 1.0903INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 1.1736 - root_mean_squared_error: 1.0833 - val_loss: 1.1192 - val_root_mean_squared_error: 1.0579\n",
      "Epoch 56/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3198 - root_mean_squared_error: 1.1488INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 1.1583 - root_mean_squared_error: 1.0763 - val_loss: 1.1036 - val_root_mean_squared_error: 1.0505\n",
      "Epoch 57/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.9301 - root_mean_squared_error: 0.9644INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 1.1404 - root_mean_squared_error: 1.0679 - val_loss: 1.0910 - val_root_mean_squared_error: 1.0445\n",
      "Epoch 58/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1928 - root_mean_squared_error: 1.0922INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 1.1276 - root_mean_squared_error: 1.0619 - val_loss: 1.0791 - val_root_mean_squared_error: 1.0388\n",
      "Epoch 59/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6517 - root_mean_squared_error: 1.2852INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 1.1157 - root_mean_squared_error: 1.0563 - val_loss: 1.0682 - val_root_mean_squared_error: 1.0335\n",
      "Epoch 60/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4686 - root_mean_squared_error: 1.2119INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 1.1035 - root_mean_squared_error: 1.0505 - val_loss: 1.0590 - val_root_mean_squared_error: 1.0291\n",
      "Epoch 61/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.9835 - root_mean_squared_error: 0.9917INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 1.0929 - root_mean_squared_error: 1.0454 - val_loss: 1.0510 - val_root_mean_squared_error: 1.0252\n",
      "Epoch 62/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.8548 - root_mean_squared_error: 0.9246INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 1.0853 - root_mean_squared_error: 1.0418 - val_loss: 1.0434 - val_root_mean_squared_error: 1.0215\n",
      "Epoch 63/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3654 - root_mean_squared_error: 1.1685INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 1.0763 - root_mean_squared_error: 1.0375 - val_loss: 1.0375 - val_root_mean_squared_error: 1.0186\n",
      "Epoch 64/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.9465 - root_mean_squared_error: 0.9729INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 1.0691 - root_mean_squared_error: 1.0340 - val_loss: 1.0323 - val_root_mean_squared_error: 1.0160\n",
      "Epoch 65/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0318 - root_mean_squared_error: 1.0158INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 1.0635 - root_mean_squared_error: 1.0313 - val_loss: 1.0270 - val_root_mean_squared_error: 1.0134\n",
      "Epoch 66/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.9665 - root_mean_squared_error: 0.9831INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 1.0570 - root_mean_squared_error: 1.0281 - val_loss: 1.0221 - val_root_mean_squared_error: 1.0110\n",
      "Epoch 67/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2469 - root_mean_squared_error: 1.1167INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 1.0517 - root_mean_squared_error: 1.0255 - val_loss: 1.0175 - val_root_mean_squared_error: 1.0087\n",
      "Epoch 68/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1524 - root_mean_squared_error: 1.0735INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 1.0463 - root_mean_squared_error: 1.0229 - val_loss: 1.0134 - val_root_mean_squared_error: 1.0067\n",
      "Epoch 69/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3023 - root_mean_squared_error: 1.1412INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 1.0419 - root_mean_squared_error: 1.0207 - val_loss: 1.0099 - val_root_mean_squared_error: 1.0049\n",
      "Epoch 70/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0130 - root_mean_squared_error: 1.0065INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 1.0386 - root_mean_squared_error: 1.0191 - val_loss: 1.0068 - val_root_mean_squared_error: 1.0034\n",
      "Epoch 71/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.8916 - root_mean_squared_error: 0.9442INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 1.0341 - root_mean_squared_error: 1.0169 - val_loss: 1.0046 - val_root_mean_squared_error: 1.0023\n",
      "Epoch 72/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0316 - root_mean_squared_error: 1.0157INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 1.0316 - root_mean_squared_error: 1.0157 - val_loss: 1.0025 - val_root_mean_squared_error: 1.0013\n",
      "Epoch 73/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.9472 - root_mean_squared_error: 0.9732INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 1.0289 - root_mean_squared_error: 1.0143 - val_loss: 1.0008 - val_root_mean_squared_error: 1.0004\n",
      "Epoch 74/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1363 - root_mean_squared_error: 1.0660INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 1.0272 - root_mean_squared_error: 1.0135 - val_loss: 0.9993 - val_root_mean_squared_error: 0.9996\n",
      "Epoch 75/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0109 - root_mean_squared_error: 1.0054INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 1.0249 - root_mean_squared_error: 1.0124 - val_loss: 0.9981 - val_root_mean_squared_error: 0.9991\n",
      "Epoch 76/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0690 - root_mean_squared_error: 1.0339INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 1.0234 - root_mean_squared_error: 1.0116 - val_loss: 0.9970 - val_root_mean_squared_error: 0.9985\n",
      "Epoch 77/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.9916 - root_mean_squared_error: 0.9958INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 1.0217 - root_mean_squared_error: 1.0108 - val_loss: 0.9961 - val_root_mean_squared_error: 0.9981\n",
      "Epoch 78/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.8484 - root_mean_squared_error: 0.9211INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 1.0204 - root_mean_squared_error: 1.0102 - val_loss: 0.9954 - val_root_mean_squared_error: 0.9977\n",
      "Epoch 79/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2413 - root_mean_squared_error: 1.1141INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 1.0194 - root_mean_squared_error: 1.0096 - val_loss: 0.9948 - val_root_mean_squared_error: 0.9974\n",
      "Epoch 80/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0625 - root_mean_squared_error: 1.0308INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 1.0184 - root_mean_squared_error: 1.0092 - val_loss: 0.9942 - val_root_mean_squared_error: 0.9971\n",
      "Epoch 81/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.9575 - root_mean_squared_error: 0.9785INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 1.0177 - root_mean_squared_error: 1.0088 - val_loss: 0.9937 - val_root_mean_squared_error: 0.9968\n",
      "Epoch 82/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0090 - root_mean_squared_error: 1.0045INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 1.0169 - root_mean_squared_error: 1.0084 - val_loss: 0.9933 - val_root_mean_squared_error: 0.9966\n",
      "Epoch 83/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2461 - root_mean_squared_error: 1.1163INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 1.0164 - root_mean_squared_error: 1.0082 - val_loss: 0.9930 - val_root_mean_squared_error: 0.9965\n",
      "Epoch 84/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0696 - root_mean_squared_error: 1.0342INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 1.0155 - root_mean_squared_error: 1.0077 - val_loss: 0.9928 - val_root_mean_squared_error: 0.9964\n",
      "Epoch 85/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1594 - root_mean_squared_error: 1.0767INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 1.0149 - root_mean_squared_error: 1.0074 - val_loss: 0.9925 - val_root_mean_squared_error: 0.9963\n",
      "Epoch 86/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.8608 - root_mean_squared_error: 0.9278INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 1.0150 - root_mean_squared_error: 1.0075 - val_loss: 0.9923 - val_root_mean_squared_error: 0.9961\n",
      "Epoch 87/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2067 - root_mean_squared_error: 1.0985INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 1.0140 - root_mean_squared_error: 1.0070 - val_loss: 0.9922 - val_root_mean_squared_error: 0.9961\n",
      "Epoch 88/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3168 - root_mean_squared_error: 1.1475INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 1.0137 - root_mean_squared_error: 1.0068 - val_loss: 0.9921 - val_root_mean_squared_error: 0.9961\n",
      "Epoch 89/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.9844 - root_mean_squared_error: 0.9922INFO:tensorflow:Assets written to: models\\simple_nn\\assets\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 1.0131 - root_mean_squared_error: 1.0065 - val_loss: 0.9921 - val_root_mean_squared_error: 0.9960\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0128 - root_mean_squared_error: 1.0064 - val_loss: 0.9921 - val_root_mean_squared_error: 0.9961\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0126 - root_mean_squared_error: 1.0063 - val_loss: 0.9922 - val_root_mean_squared_error: 0.9961\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0125 - root_mean_squared_error: 1.0062 - val_loss: 0.9923 - val_root_mean_squared_error: 0.9961\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0124 - root_mean_squared_error: 1.0062 - val_loss: 0.9923 - val_root_mean_squared_error: 0.9961\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0123 - root_mean_squared_error: 1.0061 - val_loss: 0.9923 - val_root_mean_squared_error: 0.9961\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0123 - root_mean_squared_error: 1.0061 - val_loss: 0.9923 - val_root_mean_squared_error: 0.9962\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0123 - root_mean_squared_error: 1.0061 - val_loss: 0.9923 - val_root_mean_squared_error: 0.9962\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0123 - root_mean_squared_error: 1.0061 - val_loss: 0.9924 - val_root_mean_squared_error: 0.9962\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0123 - root_mean_squared_error: 1.0061 - val_loss: 0.9924 - val_root_mean_squared_error: 0.9962\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0122 - root_mean_squared_error: 1.0061 - val_loss: 0.9925 - val_root_mean_squared_error: 0.9963\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0124 - root_mean_squared_error: 1.0062 - val_loss: 0.9926 - val_root_mean_squared_error: 0.9963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x134c7ade370>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "simple_nn = Sequential()\n",
    "simple_nn.add(InputLayer((15,)))\n",
    "simple_nn.add(Dense(2, 'relu'))\n",
    "simple_nn.add(Dense(1, 'linear'))\n",
    "\n",
    "opt = Adam(learning_rate=.1)\n",
    "cp = ModelCheckpoint('models/simple_nn', save_best_only=True)\n",
    "simple_nn.compile(optimizer=opt, loss='mse', metrics=[RootMeanSquaredError()])\n",
    "simple_nn.fit(x=X_train, y=y_train, validation_data=(X,y), callbacks=[cp], epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
